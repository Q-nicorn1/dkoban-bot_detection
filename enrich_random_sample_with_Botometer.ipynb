{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect a random sample and enrich it with Botometer and BotometerLite \n",
    "\n",
    "1. Make an output directory to write API results to and load libraries\n",
    "2. Collect tweets from Twitter API via `twarc`\n",
    "3. Select _n_ unique user IDs\n",
    "4. Enrich with Botometer scores\n",
    "5. Enrich with BotometerLite scores \n",
    "6. Merge results and output to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make an output directory to write API results to and load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from twarc import Twarc\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import random \n",
    "import twitter_col\n",
    "import botometer\n",
    "\n",
    "# make an output directory to write API responses to\n",
    "collection_name = 'random_sample_bot_scores'\n",
    "if not os.path.exists(collection_name):\n",
    "    os.makedirs(collection_name)\n",
    "    os.makedirs(collection_name + '/botometer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collect tweets via `twarc`\n",
    "\n",
    "Collect tweets in the Python terminal with the following commands:\n",
    "\n",
    "1. `twarc configure` - run this to set up your API credentials.\n",
    "2. `twarc sample > twarc_random_sample.jsonl` - run this to collect a random stream of tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select n unique user IDs.\n",
    "\n",
    "`twitter_col` is a library created by Dave Beskow that I use for parsing tweet jsons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                            | 23958 Elapsed Time: 0:00:01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the tweet json to a pandas data frame\n",
    "tweets = twitter_col.parse_twitter_json('/Users/dankoban/Documents/EM6574/random/twarc_random_sample.jsonl', \n",
    "                                    to_csv = False, sentiment = False)\n",
    "\n",
    "# filter to include only english tweets\n",
    "tweets = tweets[tweets['status_lang'] == 'en']\n",
    "\n",
    "# set seed = 1 for reproducibility and randomly sample n accounts\n",
    "random.seed(1) \n",
    "user_ids = tweets['id_str'].unique().tolist()\n",
    "user_ids = random.sample(user_ids, 10) \n",
    "len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Enrich with Botometer scores \n",
    "\n",
    "To run this code you will need a Twitter developer account and Rapid API key.  Each API result is written to an individual csv file to prevent losing results in the event a kernel dies.  Botometer allows user to check up to 17,280 Twitter accounts per day. However, I have never come close to reaching that limit due to latency of the API. It generally takes me about 2 days to pull 10,000 accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapidapi_key = \" \"\n",
    "twitter_app_auth = {\n",
    "    'consumer_key': '',\n",
    "    'consumer_secret': '',\n",
    "    'access_token': '',\n",
    "    'access_token_secret': '',\n",
    "  }\n",
    "bom = botometer.Botometer(wait_on_ratelimit=True, \n",
    "                          rapidapi_key=rapidapi_key,**twitter_app_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Iteratively check user IDs for Botometer scores\n",
    "botometer_full = []\n",
    "i = 0\n",
    "for user in user_ids:\n",
    "    i+=1\n",
    "    try:\n",
    "        result = bom.check_account(user)            \n",
    "        temp = pd.DataFrame(result)\n",
    "        temp = pd.DataFrame({'id_str': [temp['user']['user_data']['id_str']],\n",
    "                             'screen_name': [temp['user']['user_data']['screen_name']],\n",
    "                             'cap_en': [temp['cap']['english']],\n",
    "                             'cap_un': [temp['cap']['universal']],\n",
    "\n",
    "                             'astroturf_raw_en': [temp['raw_scores']['english']['astroturf']],\n",
    "                             'fake_follower_raw_en': [temp['raw_scores']['english']['fake_follower']],\n",
    "                             'financial_raw_en': [temp['raw_scores']['english']['financial']],\n",
    "                             'other_raw_en': [temp['raw_scores']['english']['other']],\n",
    "                             'overall_raw_en': [temp['raw_scores']['english']['overall']],\n",
    "                             'self_declared_raw_en': [temp['raw_scores']['english']['self_declared']],\n",
    "                             'spammer_raw_en': [temp['raw_scores']['english']['spammer']],\n",
    "\n",
    "                             'astroturf_display_en': [temp['display_scores']['english']['astroturf']],\n",
    "                             'fake_follower_display_en': [temp['display_scores']['english']['fake_follower']],\n",
    "                             'financial_display_en': [temp['display_scores']['english']['financial']],\n",
    "                             'other_display_en': [temp['display_scores']['english']['other']],\n",
    "                             'overall_display_en': [temp['display_scores']['english']['overall']],\n",
    "                             'self_declared_display_en': [temp['display_scores']['english']['self_declared']],\n",
    "                             'spammer_display_en': [temp['display_scores']['english']['spammer']],\n",
    "\n",
    "                             'astroturf_raw_un': [temp['raw_scores']['universal']['astroturf']],\n",
    "                             'fake_follower_raw_un': [temp['raw_scores']['universal']['fake_follower']],\n",
    "                             'financial_raw_un': [temp['raw_scores']['universal']['financial']],\n",
    "                             'other_raw_un': [temp['raw_scores']['universal']['other']],\n",
    "                             'overall_raw_un': [temp['raw_scores']['universal']['overall']],\n",
    "                             'self_declared_raw_un': [temp['raw_scores']['universal']['self_declared']],\n",
    "                             'spammer_raw_un': [temp['raw_scores']['universal']['spammer']],\n",
    "\n",
    "                             'astroturf_display_un': [temp['display_scores']['universal']['astroturf']],\n",
    "                             'fake_follower_display_un': [temp['display_scores']['universal']['fake_follower']],\n",
    "                             'financial_display_un': [temp['display_scores']['universal']['financial']],\n",
    "                             'other_display_un': [temp['display_scores']['universal']['other']],\n",
    "                             'overall_display_un': [temp['display_scores']['universal']['overall']],\n",
    "                             'self_declared_display_un': [temp['display_scores']['universal']['self_declared']],\n",
    "                             'spammer_display_un': [temp['display_scores']['universal']['spammer']]\n",
    "                     })\n",
    "        print(i)\n",
    "        timestr = time.strftime(\"%m%d%Y_%H%M\")\n",
    "        temp.to_csv(collection_name + '/botometer/' + str(user) + timestr + \".csv\")\n",
    "        botometer_full.append(temp)\n",
    "\n",
    "    except:\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Enrich with BotometerLite Scores\n",
    "\n",
    "BotometerLite allows for batch queries of up to 20,000 accounts per day and completes in minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function to split user ids into batches.  \n",
    "# BotometerLite accepts up to 100 user IDs per query.\n",
    "def batch(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]   \n",
    "\n",
    "# Read in the Botometer scores gathered in step 3.\n",
    "files = os.listdir(collection_name + '/botometer/')\n",
    "df_list = []\n",
    "for file in files:\n",
    "    temp = pd.read_csv(collection_name + '/botometer/' + file, \n",
    "                        dtype={'id_str': 'str'})\n",
    "    df_list.append(temp)\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "        \n",
    "user_ids = df['id_str'].unique().tolist()                \n",
    "batches = list(batch(user_ids, 100))\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blt_twitter = botometer.BotometerLite(rapidapi_key=rapidapi_key, **twitter_app_auth)\n",
    "blt_scores = []\n",
    "for batch in batches:\n",
    "    temp = blt_twitter.check_accounts_from_user_ids(batch)\n",
    "    blt_scores.append(pd.DataFrame(temp))\n",
    "blt_scores = pd.concat(blt_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine Botometer and BotometerLite scores into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of botometerLite to merge with Botometer data\n",
    "blt_scores = blt_scores.rename(columns={'user_id': 'id_str',\n",
    "                                        'botscore': 'bot_lite'})\n",
    "blt_scores['id_str'] = blt_scores['id_str'].astype('str')\n",
    "\n",
    "# merge bot scores\n",
    "merged_bot_scores = df.merge(blt_scores[['id_str', 'bot_lite']], how = 'left', on = 'id_str')\n",
    "keep_cols = ['id_str', 'cap_en', 'cap_un',\n",
    "       'astroturf_raw_en', 'fake_follower_raw_en', 'financial_raw_en',\n",
    "       'other_raw_en', 'overall_raw_en', 'self_declared_raw_en',\n",
    "       'spammer_raw_en', 'astroturf_display_en', 'fake_follower_display_en',\n",
    "       'financial_display_en', 'other_display_en', 'overall_display_en',\n",
    "       'self_declared_display_en', 'spammer_display_en', 'astroturf_raw_un',\n",
    "       'fake_follower_raw_un', 'financial_raw_un', 'other_raw_un',\n",
    "       'overall_raw_un', 'self_declared_raw_un', 'spammer_raw_un',\n",
    "       'astroturf_display_un', 'fake_follower_display_un',\n",
    "       'financial_display_un', 'other_display_un', 'overall_display_un',\n",
    "       'self_declared_display_un', 'spammer_display_un', 'bot_lite']\n",
    "merged_bot_scores = merged_bot_scores[keep_cols]\n",
    "merged_bot_scores = merged_bot_scores[merged_bot_scores['bot_lite'].notnull()]\n",
    "merged_bot_scores\n",
    "\n",
    "# merge with the user profile info\n",
    "tweets_filtered = tweets[tweets['id_str'].isin(merged_bot_scores.id_str)]\n",
    "final_df = tweets_filtered.merge(merged_bot_scores, how = 'left', on = 'id_str')\n",
    "final_df.to_csv(collection_name + '/enriched_accounts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forcenexus",
   "language": "python",
   "name": "forcenexus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
