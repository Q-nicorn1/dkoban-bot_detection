{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from numpy import std\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "import seaborn as sns \n",
    "plt.style.use('seaborn')\n",
    "\n",
    "df = pd.read_excel('data/processed_data.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = ['statuses_count', 'followers_count', 'friends_count',\n",
    "                 'favourites_count', 'listed_count']\n",
    "meta_data = df[metadata_cols]\n",
    "\n",
    "derived_feature_cols = ['tweet_freq', 'followers_growth_rate', 'friends_growth_rate',\n",
    "                        'favourites_growth_rate', 'listed_growth_rate', \n",
    "                        'follower_friend_ratio', 'follower_favorites_ratio', 'tweet_follower_ratio', \n",
    "                        'screen_name_length', 'num_digits_in_screen_name',\n",
    "                        'name_length', 'num_digits_in_name', 'num_digits_end_screen_name',\n",
    "                        'description_length', 'screen_name_likelihood']\n",
    "derived_features = df[derived_feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "meta_data_standard=StandardScaler().fit_transform(meta_data)# Gaussian Standardisation\n",
    "meta_data_standard=pd.DataFrame(meta_data_standard,columns=metadata_cols)\n",
    "derived_features_standard=StandardScaler().fit_transform(derived_features)# Gaussian Standardisation\n",
    "derived_features_standard=pd.DataFrame(derived_features_standard,columns=derived_feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_default_profile</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>tweet_freq</th>\n",
       "      <th>followers_growth_rate</th>\n",
       "      <th>friends_growth_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>follower_favorites_ratio</th>\n",
       "      <th>tweet_follower_ratio</th>\n",
       "      <th>screen_name_length</th>\n",
       "      <th>num_digits_in_screen_name</th>\n",
       "      <th>name_length</th>\n",
       "      <th>num_digits_in_name</th>\n",
       "      <th>num_digits_end_screen_name</th>\n",
       "      <th>description_length</th>\n",
       "      <th>screen_name_likelihood</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.402257</td>\n",
       "      <td>-0.014926</td>\n",
       "      <td>0.542074</td>\n",
       "      <td>-0.477201</td>\n",
       "      <td>-0.008162</td>\n",
       "      <td>-0.138500</td>\n",
       "      <td>-0.017317</td>\n",
       "      <td>-0.007543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015606</td>\n",
       "      <td>-0.018669</td>\n",
       "      <td>-0.690522</td>\n",
       "      <td>-0.458132</td>\n",
       "      <td>-0.292792</td>\n",
       "      <td>-0.165977</td>\n",
       "      <td>-0.441154</td>\n",
       "      <td>0.379984</td>\n",
       "      <td>-0.770636</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.511078</td>\n",
       "      <td>-0.010610</td>\n",
       "      <td>1.697445</td>\n",
       "      <td>-0.510996</td>\n",
       "      <td>-0.055039</td>\n",
       "      <td>-0.146914</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>0.998811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012485</td>\n",
       "      <td>-0.018390</td>\n",
       "      <td>0.479344</td>\n",
       "      <td>-0.458132</td>\n",
       "      <td>2.521351</td>\n",
       "      <td>-0.165977</td>\n",
       "      <td>-0.441154</td>\n",
       "      <td>1.502738</td>\n",
       "      <td>1.112019</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.424411</td>\n",
       "      <td>-0.016429</td>\n",
       "      <td>-0.269437</td>\n",
       "      <td>-0.452793</td>\n",
       "      <td>-0.056551</td>\n",
       "      <td>-0.129266</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>-0.109824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016164</td>\n",
       "      <td>-0.018827</td>\n",
       "      <td>-0.690522</td>\n",
       "      <td>1.968166</td>\n",
       "      <td>-1.277743</td>\n",
       "      <td>-0.165977</td>\n",
       "      <td>2.110246</td>\n",
       "      <td>-1.210585</td>\n",
       "      <td>-0.444243</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.472891</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.790513</td>\n",
       "      <td>-0.519394</td>\n",
       "      <td>-0.061087</td>\n",
       "      <td>-0.149587</td>\n",
       "      <td>-0.016511</td>\n",
       "      <td>0.088230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014570</td>\n",
       "      <td>-0.018672</td>\n",
       "      <td>1.649210</td>\n",
       "      <td>-0.458132</td>\n",
       "      <td>-0.574207</td>\n",
       "      <td>-0.165977</td>\n",
       "      <td>-0.441154</td>\n",
       "      <td>0.342559</td>\n",
       "      <td>1.164265</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.453512</td>\n",
       "      <td>-0.016407</td>\n",
       "      <td>0.178441</td>\n",
       "      <td>-0.447583</td>\n",
       "      <td>-0.027820</td>\n",
       "      <td>-0.152851</td>\n",
       "      <td>-0.019099</td>\n",
       "      <td>-0.122647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016164</td>\n",
       "      <td>-0.018934</td>\n",
       "      <td>0.869299</td>\n",
       "      <td>-0.458132</td>\n",
       "      <td>0.270036</td>\n",
       "      <td>-0.165977</td>\n",
       "      <td>-0.441154</td>\n",
       "      <td>0.829085</td>\n",
       "      <td>1.081450</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_default_profile  verified  statuses_count  followers_count  \\\n",
       "0                    0         0       -0.402257        -0.014926   \n",
       "1                    0         0       -0.511078        -0.010610   \n",
       "2                    0         0       -0.424411        -0.016429   \n",
       "3                    0         0       -0.472891        -0.014573   \n",
       "4                    0         0       -0.453512        -0.016407   \n",
       "\n",
       "   friends_count  favourites_count  listed_count  tweet_freq  \\\n",
       "0       0.542074         -0.477201     -0.008162   -0.138500   \n",
       "1       1.697445         -0.510996     -0.055039   -0.146914   \n",
       "2      -0.269437         -0.452793     -0.056551   -0.129266   \n",
       "3       0.790513         -0.519394     -0.061087   -0.149587   \n",
       "4       0.178441         -0.447583     -0.027820   -0.152851   \n",
       "\n",
       "   followers_growth_rate  friends_growth_rate  ...  follower_favorites_ratio  \\\n",
       "0              -0.017317            -0.007543  ...                 -0.015606   \n",
       "1              -0.000919             0.998811  ...                 -0.012485   \n",
       "2              -0.018716            -0.109824  ...                 -0.016164   \n",
       "3              -0.016511             0.088230  ...                 -0.014570   \n",
       "4              -0.019099            -0.122647  ...                 -0.016164   \n",
       "\n",
       "   tweet_follower_ratio  screen_name_length  num_digits_in_screen_name  \\\n",
       "0             -0.018669           -0.690522                  -0.458132   \n",
       "1             -0.018390            0.479344                  -0.458132   \n",
       "2             -0.018827           -0.690522                   1.968166   \n",
       "3             -0.018672            1.649210                  -0.458132   \n",
       "4             -0.018934            0.869299                  -0.458132   \n",
       "\n",
       "   name_length  num_digits_in_name  num_digits_end_screen_name  \\\n",
       "0    -0.292792           -0.165977                   -0.441154   \n",
       "1     2.521351           -0.165977                   -0.441154   \n",
       "2    -1.277743           -0.165977                    2.110246   \n",
       "3    -0.574207           -0.165977                   -0.441154   \n",
       "4     0.270036           -0.165977                   -0.441154   \n",
       "\n",
       "   description_length  screen_name_likelihood    bot  \n",
       "0            0.379984               -0.770636  False  \n",
       "1            1.502738                1.112019  False  \n",
       "2           -1.210585               -0.444243  False  \n",
       "3            0.342559                1.164265  False  \n",
       "4            0.829085                1.081450  False  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_metadata_cols = ['has_default_profile', 'verified']\n",
    "binary_metadata = df[binary_metadata_cols]\n",
    "response = df['bot']\n",
    "\n",
    "merge = pd.concat([binary_metadata.reset_index(drop=True), meta_data_standard], axis=1)\n",
    "merge = pd.concat([merge.reset_index(drop=True), derived_features_standard], axis=1)\n",
    "merge = pd.concat([merge.reset_index(drop=True), response], axis=1)\n",
    "merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a random forrest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated bots: 65\n",
      "f1 score: 0.681 +/- 0.206\n",
      "precision: 0.941 +/- 0.118\n",
      "recall: 0.578 +/- 0.214\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state = 1, shuffle = True)\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion=\"gini\")\n",
    "features = binary_metadata_cols + metadata_cols + derived_feature_cols\n",
    "train_X = merge[features]\n",
    "train_y = merge.bot\n",
    "f1_scores = cross_val_score(rf, train_X, train_y, scoring = 'f1', cv = cv)\n",
    "f1_scores = list(f1_scores)\n",
    "precision_scores = cross_val_score(rf, train_X, train_y, scoring = 'precision', cv = cv)\n",
    "precision_scores = list(precision_scores)\n",
    "recall_scores = cross_val_score(rf, train_X, train_y, scoring = 'recall', cv = cv)\n",
    "recall_scores = list(recall_scores)\n",
    "\n",
    "print(\"Number of annotated bots: \" + str(len(merge[merge['bot'] == True])))\n",
    "print('f1 score: ' + str(mean(f1_scores))[0:5] + \" +/- \" + str(std(f1_scores))[0:5])\n",
    "print('precision: ' + str(mean(precision_scores))[0:5] + \" +/- \" + str(std(precision_scores))[0:5])\n",
    "print('recall: '+ str(mean(recall_scores))[0:5] + \" +/- \" + str(std(recall_scores))[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict continuous values the same way BotometerLite presents results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bot</th>\n",
       "      <th>sklearn_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>True</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>True</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182</th>\n",
       "      <td>True</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>True</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7184</th>\n",
       "      <td>True</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7185 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bot  sklearn_p\n",
       "0     False       0.00\n",
       "1     False       0.01\n",
       "2     False       0.00\n",
       "3     False       0.00\n",
       "4     False       0.00\n",
       "...     ...        ...\n",
       "7180   True       0.08\n",
       "7181   True       0.71\n",
       "7182   True       0.06\n",
       "7183   True       0.36\n",
       "7184   True       0.83\n",
       "\n",
       "[7185 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = cross_val_predict(rf, train_X, train_y, cv=cv, method='predict_proba')\n",
    "df['sklearn_p'] = list(proba[:,1])\n",
    "df[['bot', 'sklearn_p']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return a/b  \n",
    "\n",
    "def tune_threshold(data, k):\n",
    "    score_threshold = k\n",
    "    benchmark = pd.DataFrame({'sklearn_prediction': data['sklearn_p'] >= score_threshold,\n",
    "                              'bot': data['bot']})\n",
    "    true_pos = sum((benchmark['sklearn_prediction'] == True) & (benchmark['bot'] == True))\n",
    "    false_pos = sum((benchmark['sklearn_prediction'] == True) & (benchmark['bot'] == False))\n",
    "    true_neg = sum((benchmark['sklearn_prediction'] == False) & (benchmark['bot'] == False))\n",
    "    false_neg = sum((benchmark['sklearn_prediction'] == False) & (benchmark['bot'] == True))\n",
    "    precision = divide(true_pos,(true_pos + false_pos))\n",
    "    recall = divide(true_pos,(true_pos + false_neg))\n",
    "    f1 = 2*divide(precision*recall, precision+recall)\n",
    "    return f1\n",
    "\n",
    "f1_scores = []\n",
    "for k in range(0,100):\n",
    "    f1 = pd.DataFrame({'k': [k/100],\n",
    "                       'f1': tune_threshold(data = df, k = k/100)})    \n",
    "    f1_scores.append(f1)\n",
    "f1_scores = pd.concat(f1_scores)\n",
    "\n",
    "score_threshold = list(f1_scores['k'][f1_scores['f1'] == max(f1_scores['f1'])][0])\n",
    "score_threshold = score_threshold[0]\n",
    "benchmark = pd.DataFrame({'sklearn_prediction': df['sklearn_p'] >= score_threshold,\n",
    "                          'bot': df['bot']})\n",
    "true_pos = sum((benchmark['sklearn_prediction'] == True) & (benchmark['bot'] == True))\n",
    "false_pos = sum((benchmark['sklearn_prediction'] == True) & (benchmark['bot'] == False))\n",
    "true_neg = sum((benchmark['sklearn_prediction'] == False) & (benchmark['bot'] == False))\n",
    "false_neg = sum((benchmark['sklearn_prediction'] == False) & (benchmark['bot'] == True))\n",
    "\n",
    "precision = true_pos/(true_pos + false_pos)\n",
    "recall = true_pos/(true_pos + false_neg)\n",
    "\n",
    "print(str(f1_scores[f1_scores['f1'] == max(f1_scores['f1'])]))\n",
    "print(\"\")\n",
    "print(\"Precision - sklearn predicted bot \" + str(sum(benchmark['sklearn_prediction'] == True)) + \" times and was correct \" + str(true_pos) + \" times: \" + str(precision)[0:5])\n",
    "print(\"Recall - sklearn predicted \" + str(true_pos) + \" out of the \" + str(sum(benchmark['bot'] == True)) + \" bots: \" + str(recall)[0:5])\n",
    "print(\"\")\n",
    "print(\"sklearn's total accuracy was \" + str((true_pos + true_neg)/len(benchmark)) + \"%\")\n",
    "print(\"sklearn's F1 score was \" + str(2*(precision*recall)/(precision+recall))[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BotometerLite Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return a/b  \n",
    "\n",
    "def tune_threshold(data, k):\n",
    "    bot_lite_threshold = k\n",
    "    benchmark = pd.DataFrame({'bot_lite_prediction': data['bot_lite'] >= bot_lite_threshold,\n",
    "                              'bot': data['bot']})\n",
    "    true_pos = sum((benchmark['bot_lite_prediction'] == True) & (benchmark['bot'] == True))\n",
    "    false_pos = sum((benchmark['bot_lite_prediction'] == True) & (benchmark['bot'] == False))\n",
    "    true_neg = sum((benchmark['bot_lite_prediction'] == False) & (benchmark['bot'] == False))\n",
    "    false_neg = sum((benchmark['bot_lite_prediction'] == False) & (benchmark['bot'] == True))\n",
    "    precision = divide(true_pos,(true_pos + false_pos))\n",
    "    recall = divide(true_pos,(true_pos + false_neg))\n",
    "    f1 = 2*divide(precision*recall, precision+recall)\n",
    "    return f1\n",
    "\n",
    "f1_scores = []\n",
    "for k in range(0,100):\n",
    "    f1 = pd.DataFrame({'k': [k/100],\n",
    "                       'f1': tune_threshold(data = df, k = k/100)})    \n",
    "    f1_scores.append(f1)\n",
    "f1_scores = pd.concat(f1_scores)\n",
    "\n",
    "bot_lite_threshold = f1_scores['k'][f1_scores['f1'] == max(f1_scores['f1'])][0]\n",
    "benchmark = pd.DataFrame({'bot_lite_prediction': df['bot_lite'] >= bot_lite_threshold,\n",
    "                          'bot': df['bot']})\n",
    "true_pos = sum((benchmark['bot_lite_prediction'] == True) & (benchmark['bot'] == True))\n",
    "false_pos = sum((benchmark['bot_lite_prediction'] == True) & (benchmark['bot'] == False))\n",
    "true_neg = sum((benchmark['bot_lite_prediction'] == False) & (benchmark['bot'] == False))\n",
    "false_neg = sum((benchmark['bot_lite_prediction'] == False) & (benchmark['bot'] == True))\n",
    "\n",
    "precision = true_pos/(true_pos + false_pos)\n",
    "recall = true_pos/(true_pos + false_neg)\n",
    "\n",
    "print(str(f1_scores[f1_scores['f1'] == max(f1_scores['f1'])]))\n",
    "print(\"\")\n",
    "print(\"Precision - BotometerLite predicted bot \" + str(sum(benchmark['bot_lite_prediction'] == True)) + \" times and was correct \" + str(true_pos) + \" times: \" + str(precision)[0:5])\n",
    "print(\"Recall - BotometerLite predicted \" + str(true_pos) + \" out of the \" + str(sum(benchmark['bot'] == True)) + \" bots: \" + str(recall)[0:5])\n",
    "print(\"\")\n",
    "print(\"BotometerLite's total accuracy was \" + str((true_pos + true_neg)/len(benchmark)) + \"%\")\n",
    "print(\"BotometerLite's F1 score was \" + str(2*(precision*recall)/(precision+recall))[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus material - verify precision and recall corrections are done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = binary_metadata_cols + metadata_cols + derived_feature_cols\n",
    "train, test = train_test_split(merge, test_size = 0.2)\n",
    "train_X = train[features]\n",
    "train_y = train.bot\n",
    "test_X = test[features] \n",
    "test_y = test.bot  \n",
    "model=RandomForestClassifier(n_estimators=100, n_jobs=-1, criterion=\"gini\")\n",
    "model.fit(train_X,train_y)\n",
    "prediction=model.predict(test_X)\n",
    "print('The accuracy of the Random Forrest Model is',metrics.accuracy_score(prediction,test_y))\n",
    "cm = metrics.confusion_matrix(test_y, prediction)\n",
    "true_pos = cm[1,1]\n",
    "true_neg = cm[0,0]\n",
    "false_pos = cm[0,1]\n",
    "false_neg = cm[1,0]\n",
    "precision = true_pos/(true_pos + false_pos)\n",
    "recall = true_pos/(true_pos + false_neg)\n",
    "\n",
    "print(\"When we check precision of our RFM model against the test data set, \" + str(len(test_y)) + \" accounts\")\n",
    "print(\"\")\n",
    "print(\"Precision - We predicted fake follower \" + str(cm[1,1] + cm[0,1]) + \" times and were correct \" + str(cm[1,1]) + \" times: \" + str(cm[1,1]/(cm[1,1] + cm[0,1]))[0:5])\n",
    "print(\"Recall - We predicted \" + str(cm[1,1]) + \" out of the \" + str(cm[1,1] + cm[1,0]) + \" fake followers: \" + str(recall)[0:5])\n",
    "print(\"\")\n",
    "print(\"Our total accuracy was \" + str((cm[0,0] + cm[1,1])/len(test_y))[0:5])\n",
    "print(\"Our F1 score was \" + str(2*(precision*recall)/(precision+recall))[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(test_y, prediction)\n",
    "cm = metrics.confusion_matrix(test_y, prediction)\n",
    "\n",
    "true_neg = str(cm[0,0]) + \"/\" + str(cm[0,0] + cm[1,0]) + \" (\" + str(cm[0,0]/(cm[0,0] + cm[1,0]))[0:5] + \")\"\n",
    "false_pos = str(cm[0,1]) + \"/\" + str(cm[0,1] + cm[1,1]) + \" (\" + str(cm[0,1]/(cm[0,1] + cm[1,1]))[0:5] + \")\"\n",
    "false_neg = str(cm[1,0]) + \"/\" + str(cm[1,0] + cm[0,0]) + \" (\" + str(cm[1,0]/(cm[1,0] + cm[0,0]))[0:5] + \")\"\n",
    "true_pos = str(cm[1,1]) + \"/\" + str(cm[1,1] + cm[0,1]) + \" (\" + str(cm[1,1]/(cm[1,1] + cm[0,1]))[0:5] + \")\"\n",
    "\n",
    "conf_matrix = pd.DataFrame({'Not Bot': [true_neg, false_neg],\n",
    "                            'Bot': [false_pos, true_pos],\n",
    "                            'Support': [cm[0,0] + cm[0,1], cm[1,0] + cm[1,1]]},\n",
    "                    index = ['Not Bot', 'Bot'])\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(test_y,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.feature_importances_,index=train_X.columns).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forcenexus",
   "language": "python",
   "name": "forcenexus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
